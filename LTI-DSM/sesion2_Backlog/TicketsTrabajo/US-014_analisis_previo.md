# AnÃ¡lisis Previo - US-014: Ranking SemÃ¡ntico

> AnÃ¡lisis detallado de recursos, distribuciÃ³n de trabajo y dependencias para la User Story US-014  
> Fecha: Julio 2025  
> Product Manager: [Nombre]  
> Tech Lead: [Nombre]

---

## ğŸ“‹ Resumen Ejecutivo

**US-014: Ranking SemÃ¡ntico** es la **funcionalidad diferenciadora clave** del producto que requiere **3 sprints (6 semanas)** para implementaciÃ³n completa. Requiere equipo especializado en AI/ML y arquitectura vectorial escalable. La distribuciÃ³n estÃ¡ dominada por Backend/AI (80%) con componente Frontend sofisticado para explicabilidad.

---

## ğŸ“Š Desglose de Tickets y Estimaciones

| **Ticket** | **DescripciÃ³n** | **Equipo** | **SP** | **DÃ­as** | **Complejidad** |
|------------|-----------------|------------|--------|----------|-----------------|
| **T001_formulario** | Infraestructura de embeddings y vectores | AI/ML + Backend | 8 SP | 8-10 dÃ­as | **Muy Alta** |
| **T002_validacion** | Algoritmo validaciÃ³n y calibraciÃ³n scores | AI/ML | 5 SP | 5-7 dÃ­as | **Alta** |
| **T003_guardado** | Sistema persistencia scores y rankings | Backend | 4 SP | 4-5 dÃ­as | Media |
| **T004_interfaz** | Interfaz ranking y explicabilidad | Frontend | 4 SP | 4-5 dÃ­as | **Alta** |
| **TOTAL** | | | **21 SP** | **21-27 dÃ­as** | |

---

## ğŸ‘¥ Recursos Necesarios para 3 Sprints

### **ğŸ¯ ConfiguraciÃ³n MÃ­nima:**
- **1 Senior ML Engineer** - 100% dedicaciÃ³n (especialista embeddings/NLP)
- **1 Senior Backend Developer** - 80% dedicaciÃ³n (arquitectura vectorial)
- **1 Senior Frontend Developer** - 60% dedicaciÃ³n (UI explicabilidad)
- **0.5 Data Scientist** - calibraciÃ³n y mÃ©tricas
- **0.5 DevOps Engineer** - infraestructura ML/vectorial
- **0.3 Product Owner** - validaciÃ³n criterios de negocio

### **ğŸš€ ConfiguraciÃ³n Ã“ptima:**
- **1 Senior ML Engineer** + **1 ML Engineer** (para A/B testing)
- **1 Senior Backend Developer** + **1 Backend Developer** (APIs + DB)
- **1 Senior Frontend Developer** + **0.5 UX Designer** (explicabilidad)
- **0.5 Data Scientist** - experimentos y mÃ©tricas
- **0.5 DevOps Engineer** - scaling y monitoring
- **0.3 Product Owner**
- **0.2 QA Engineer** - testing algorithmic bias

---

## ğŸ“ˆ DistribuciÃ³n de Trabajo por Equipos

### **Por Story Points:**
| **Equipo** | **Story Points** | **Porcentaje** | **Responsabilidades** |
|------------|------------------|----------------|-----------------------|
| **AI/ML** | 13 SP (T001+T002) | **62%** | Embeddings, algoritmos, calibraciÃ³n |
| **Backend** | 4 SP (T003) | **19%** | Persistencia vectorial, APIs performance |
| **Frontend** | 4 SP (T004) | **19%** | UI explicabilidad, visualizaciÃ³n scores |

### **Por Complejidad TÃ©cnica:**
| **Equipo** | **Muy Alta** | **Alta** | **Media** | **Baja** |
|------------|--------------|----------|-----------|----------|
| **AI/ML** | 60% (T001) | 40% (T002) | 0% | 0% |
| **Backend** | 0% | 0% | 100% (T003) | 0% |
| **Frontend** | 0% | 100% (T004) | 0% | 0% |

### **Por Tiempo Real:**
- **AI/ML**: 13-17 dÃ­as de trabajo efectivo
- **Backend**: 4-5 dÃ­as de trabajo efectivo (alta especializaciÃ³n)
- **Frontend**: 4-5 dÃ­as de trabajo efectivo (UX compleja)
- **InvestigaciÃ³n/Experimentos**: 5-7 dÃ­as adicionales

---

## ğŸ”— AnÃ¡lisis de Dependencias

### **Dependencias CrÃ­ticas:**
```
Research ML Models â†’ T001 (Embeddings) â†’ T002 (Algoritmo) â†’ T003 (Persistencia) â†’ T004 (Interfaz)
                                      â†“
                              T003 (Database Vectorial) â† Arquitectura Performance
```

### **Dependencias Externas CrÃ­ticas:**
- ğŸ”´ **Servicios ML** - OpenAI API, HuggingFace, Sentence-BERT
- ğŸ”´ **Base de datos vectorial** - Pinecone, Weaviate, o Elasticsearch con vectores
- ğŸ”´ **US-008 completada** - datos de CVs parseados para embeddings
- ğŸ”´ **Infraestructura GPU** - para modelos locales (alternativa a APIs)
- âœ… **Cache system** - Redis para scores frecuentes
- âœ… **Monitoring ML** - mÃ©tricas de modelo y drift detection

### **Secuencia Ã“ptima de Desarrollo:**

#### **ğŸŸ¦ Sprint 1 (Semanas 1-2): Research & Infrastructure**
**DÃ­as 1-4: InvestigaciÃ³n ML**
- ğŸ” **Spike**: EvaluaciÃ³n modelos embeddings (OpenAI vs. Sentence-BERT vs. multilingual)
- ğŸ” **Spike**: Testing accuracy con CVs+vacantes reales
- ğŸ” **Spike**: Performance y costos por embedding

**DÃ­as 5-10: Infrastructure Setup**
- âœ… **T001: Embeddings** - INICIO (setup pipeline, APIs)
- âœ… **Vector DB setup** - configuraciÃ³n Pinecone/Elasticsearch
- âœ… **Monitoring setup** - mÃ©tricas ML y performance

#### **ğŸŸ¦ Sprint 2 (Semanas 3-4): Core Algorithm**
**DÃ­as 11-15: Embeddings Pipeline**
- âœ… **T001: Embeddings** - COMPLETAR (generaciÃ³n, storage, cache)
- âœ… **T002: Algoritmo** - DESARROLLO (similarity, ranking)
- âœ… **T003: Persistencia** - INICIO (schema scores)

**DÃ­as 16-20: Algorithm Tuning**
- âœ… **T002: Algoritmo** - CALIBRACIÃ“N con datos reales
- âœ… **T003: Persistencia** - DESARROLLO (APIs, cache)
- âœ… **Integration testing** - pipeline completo

#### **ğŸŸ¦ Sprint 3 (Semanas 5-6): UI & Production**
**DÃ­as 21-25: Interface Development**
- âœ… **T002: Algoritmo** - FINALIZAR (A/B testing setup)
- âœ… **T003: Persistencia** - COMPLETAR (optimization)
- âœ… **T004: Interfaz** - DESARROLLO (ranking UI, explicabilidad)

**DÃ­as 26-30: Production Ready**
- âœ… **T004: Interfaz** - COMPLETAR (UX testing)
- âœ… **Performance optimization** - latencia <500ms
- âœ… **Production deployment** - monitoring, alertas

---

## âš ï¸ GestiÃ³n de Riesgos (CRÃTICA)

### **Riesgos de Impacto CrÃ­tico:**

| **Riesgo** | **Probabilidad** | **Impacto** | **MitigaciÃ³n** |
|------------|------------------|-------------|----------------|
| **Accuracy modelo <70%** | Media | **CrÃ­tico** | Spike extensivo dÃ­a 1-4, mÃºltiples modelos |
| **Latencia >2 segundos** | Alta | **CrÃ­tico** | Arquitectura cache + precompute rankings |
| **Costos ML API excesivos** | Alta | Alto | Budget cap + modelos locales como backup |
| **Bias algorÃ­tmico** | Media | **CrÃ­tico** | Testing diversidad, auditorÃ­a AI ethics |
| **Explicabilidad insuficiente** | Media | Alto | UX research, A/B testing interfaces |
| **Escalabilidad vectorial** | Media | Alto | Sharding estrategia, DB vectorial escalable |

### **Riesgos TÃ©cnicos EspecÃ­ficos:**
- **Embeddings multi-idioma**: Accuracy puede variar por idioma
- **Cold start**: Nuevas vacantes sin histÃ³rico de matches
- **Data drift**: Modelos pueden degradarse con el tiempo
- **Vector dimensionality**: Balance accuracy vs. storage/performance

---

## ğŸ”¬ InvestigaciÃ³n TÃ©cnica CrÃ­tica

### **Spike 1: Model Selection (3-4 dÃ­as)**
**Modelos a evaluar:**
- **OpenAI text-embedding-ada-002**: $0.0001 per 1K tokens, 1536 dim, multilingual
- **Sentence-BERT multilingual**: Free, self-hosted, 768 dim
- **BGE-M3**: Nuevo SOTA, multilingual, free pero requiere GPU
- **Cohere Embed**: $0.0001 per 1K tokens, buena calidad

**Criterios de evaluaciÃ³n:**
- **Accuracy**: Correlation con manual rankings (target >0.8)
- **MultilingÃ¼e**: Performance en ES, EN, FR, DE, IT
- **Performance**: Latencia embedding generation (<1 seg)
- **Costo**: Budget sustainable para scaling
- **Maintenance**: Self-hosted vs. API reliability

### **Spike 2: Algorithm Design (2-3 dÃ­as)**
**Enfoques a evaluar:**
- **Cosine similarity simple**: Baseline rÃ¡pido
- **Weighted scoring**: Skills vs. Experience vs. Location
- **Learning-to-rank**: ML para optimizar ranking
- **Hybrid approach**: Semantic + traditional filters

### **Spike 3: Vector Database (1-2 dÃ­as)**
**Opciones:**
- **Pinecone**: Managed, $70/month starter, fÃ¡cil scaling
- **Weaviate**: Open source + cloud, mÃ¡s control
- **Elasticsearch**: Ya familiar, vector support reciente
- **Chroma**: Open source, lightweight, good for POC

---

## ğŸ’¡ Recomendaciones para Ã‰xito de 3 Sprints

### **ğŸ¯ Setup Pre-Sprint 1:**
1. **Dataset real CVs+Vacantes** para testing (200+ pares)
2. **Accounts ML services** configuradas con budgets
3. **Manual rankings** de referencia (gold standard)
4. **Performance benchmarks** definidos
5. **Ethics/Bias guidelines** para AI fairness

### **ğŸš€ Durante Desarrollo:**
1. **Spikes OBLIGATORIOS** primeros 4 dÃ­as
2. **A/B testing framework** desde Sprint 2
3. **Performance monitoring** cada commit
4. **Bias testing** con datos demogrÃ¡ficos
5. **Business validation** weekly con recruiters reales

### **ğŸ“Š MÃ©tricas de Seguimiento:**
- **Accuracy**: Correlation >0.8 con manual rankings
- **Performance**: <500ms query time para 1000 candidatos
- **Relevance**: Top 5 candidates include 80% of manual picks
- **Bias**: No discriminaciÃ³n por gÃ©nero, edad, origen
- **Explainability**: Users understand 80% of score factors

---

## ğŸ† ConclusiÃ³n y Viabilidad

### **ğŸš¨ ALTA COMPLEJIDAD - Requiere 3 Sprints con:**
- **Equipo ML especializado**: Experience en embeddings y NLP
- **InvestigaciÃ³n extensiva**: 25% tiempo en spikes y experimentos
- **Infraestructura robusta**: Vector DB, cache, monitoring ML
- **ValidaciÃ³n continua**: Business value + technical metrics

### **ğŸ¯ Factores CrÃ­ticos de Ã‰xito:**
1. **Model selection correcta** - accuracy vs. cost balance
2. **Algorithm calibration** - business rules + ML optimization
3. **Performance architecture** - sub-second query times
4. **Explainability UX** - users trust and understand rankings
5. **Bias prevention** - fair and ethical AI implementation

### **ğŸ“ˆ Criterios de AceptaciÃ³n:**
- **Funcionalidad**: Ranking semÃ¡ntico end-to-end
- **Accuracy**: >80% correlation con expert rankings
- **Performance**: <500ms ranking 1000 candidatos
- **Explainability**: Score factors clearly visible
- **Fairness**: No bias en protected characteristics

### **ğŸš¨ SeÃ±ales de Alerta:**
- Accuracy <70% despuÃ©s de 2 semanas â†’ Revaluar approach
- Latency >2 segundos â†’ RediseÃ±ar arquitectura
- Costos >$1000/month â†’ Switch a modelos locales
- Users don't trust rankings â†’ UX research needed
- Bias detected â†’ Stop deployment hasta mitigation

### **ğŸ’° Consideraciones de Costo:**
- **OpenAI API**: ~$200-500/month para 10K matches/dÃ­a
- **Vector DB**: ~$100-300/month dependiendo de soluciÃ³n
- **Infrastructure**: ~$200-400/month para GPU instances
- **Total estimate**: $500-1200/month operational costs

---

**Ãšltima actualizaciÃ³n**: 13/07/2025  
**PrÃ³xima revisiÃ³n**: Pre-Sprint Planning
